{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys, os\n",
    "import glob\n",
    "from skimage.feature import hog\n",
    "from scipy.ndimage.measurements import label\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiff/.conda/envs/carnd-term1/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from myLib.featureExtraction  import *\n",
    "from myLib.search_window      import *\n",
    "from myLib.general_utils                 import *\n",
    "from myLib.proj_lane   import *\n",
    "from myLib.proj_pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#from utils.featureExtraction import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VehicleDetector:\n",
    "    def __init__(self, model_file):\n",
    "        # Loading Model Parameters\n",
    "        dist_pickle    = pickle.load( open(model_file, \"rb\" ) )\n",
    "        self.svc            = dist_pickle[\"svc\"]\n",
    "        self.X_scaler       = dist_pickle[\"X_scaler\"]\n",
    "        self.color_space    = dist_pickle[\"color_space\"]\n",
    "        self.orient         = dist_pickle[\"orient\"]\n",
    "        self.pix_per_cell   = dist_pickle[\"pix_per_cell\"]\n",
    "        self.cell_per_block = dist_pickle[\"cell_per_block\"]\n",
    "        self.spatial_size   = dist_pickle[\"spatial_size\"]\n",
    "        self.hist_bins      = dist_pickle[\"hist_bins\"]\n",
    "        self.hog_channel    = dist_pickle[\"hog_channel\"]\n",
    "        # Current HeatMap\n",
    "        self.heatmap = None\n",
    "\n",
    "        # Heat Image for the Last Three Frames\n",
    "        self.heat_images = deque(maxlen=3)\n",
    "\n",
    "        # Current Frame Count\n",
    "        self.frame_count = 0\n",
    "        self.full_frame_processing_interval = 10\n",
    "\n",
    "        # Xstart\n",
    "        self.xstart = 600\n",
    "\n",
    "        # Various Scales\n",
    "        self.ystart_ystop_scale = [(360, 560, 1.5), (400, 600, 1.8), (440, 700, 2.5)]\n",
    "\n",
    "        # Kernal For Dilation\n",
    "        self.kernel = np.ones((50, 50))\n",
    "\n",
    "        # Threshold for Heatmap\n",
    "        self.threshold = 2\n",
    "\n",
    "    def find_cars(self, img):\n",
    "        X_scaler = self.X_scaler\n",
    "        orient = self.orient\n",
    "        pix_per_cell = self.pix_per_cell\n",
    "        cell_per_block = self.cell_per_block\n",
    "        spatial_size = self.spatial_size\n",
    "        hist_bins = self.hist_bins\n",
    "        svc = self.svc\n",
    "\n",
    "        box_list = []\n",
    "\n",
    "        draw_img = np.copy(img)\n",
    "        img = img.astype(np.float32) / 255\n",
    "\n",
    "        if self.frame_count % self.full_frame_processing_interval == 0:\n",
    "            mask = np.ones_like(img[:, :, 0])\n",
    "        else:\n",
    "            mask = np.sum(np.array(self.heat_images), axis=0)\n",
    "            mask[(mask > 0)] = 1\n",
    "            mask = cv2.dilate(mask, self.kernel, iterations=1)\n",
    "\n",
    "        self.frame_count += 1\n",
    "\n",
    "        for (ystart, ystop, scale) in self.ystart_ystop_scale:\n",
    "\n",
    "            nonzero = mask.nonzero()\n",
    "            nonzeroy = np.array(nonzero[0])\n",
    "            nonzerox = np.array(nonzero[1])\n",
    "\n",
    "            if len(nonzeroy) != 0:\n",
    "                ystart = max(np.min(nonzeroy), ystart)\n",
    "                ystop = min(np.max(nonzeroy), ystop)\n",
    "            if len(nonzeroy) != 0:\n",
    "                xstart = max(np.min(nonzerox), self.xstart)\n",
    "                xstop = np.max(nonzerox)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            if xstop <= xstart or ystop <= ystart:\n",
    "                continue\n",
    "\n",
    "            img_tosearch = img[ystart:ystop, xstart:xstop, :]\n",
    "            #ctrans_tosearch = convert_color(img_tosearch, conv='RGB2YCrCb')\n",
    "            ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2YCrCb)\n",
    "            if scale != 1:\n",
    "                imshape = ctrans_tosearch.shape\n",
    "                ys = np.int(imshape[1] / scale)\n",
    "                xs = np.int(imshape[0] / scale)\n",
    "                if (ys < 1 or xs < 1):\n",
    "                    continue\n",
    "                ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1] / scale), np.int(imshape[0] / scale)))\n",
    "\n",
    "            if ctrans_tosearch.shape[0] < 64 or ctrans_tosearch.shape[1] < 64:\n",
    "                continue\n",
    "\n",
    "            ch1 = ctrans_tosearch[:, :, 0]\n",
    "            ch2 = ctrans_tosearch[:, :, 1]\n",
    "            ch3 = ctrans_tosearch[:, :, 2]\n",
    "\n",
    "            # Define blocks and steps as above\n",
    "            nxblocks = (ch1.shape[1] // pix_per_cell) - 1\n",
    "            nyblocks = (ch1.shape[0] // pix_per_cell) - 1\n",
    "            nfeat_per_block = orient * cell_per_block ** 2\n",
    "            # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "            window = 64\n",
    "            nblocks_per_window = (window // pix_per_cell) - 1\n",
    "            cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "            nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "            nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "\n",
    "            # Compute individual channel HOG features for the entire image\n",
    "            hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "            hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "            hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "\n",
    "            for xb in range(nxsteps + 1):\n",
    "                for yb in range(nysteps + 1):\n",
    "                    ypos = yb * cells_per_step\n",
    "                    xpos = xb * cells_per_step\n",
    "\n",
    "                    # Extract HOG for this patch\n",
    "                    hog_feat1 = hog1[ypos:ypos + nblocks_per_window, xpos:xpos + nblocks_per_window].ravel()\n",
    "                    hog_feat2 = hog2[ypos:ypos + nblocks_per_window, xpos:xpos + nblocks_per_window].ravel()\n",
    "                    hog_feat3 = hog3[ypos:ypos + nblocks_per_window, xpos:xpos + nblocks_per_window].ravel()\n",
    "                    hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "                    xleft = xpos * pix_per_cell\n",
    "                    ytop = ypos * pix_per_cell\n",
    "\n",
    "                    # Extract the image patch\n",
    "                    subimg = ctrans_tosearch[ytop:ytop + window, xleft:xleft + window]\n",
    "\n",
    "                    # Get color features\n",
    "                    spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "                    hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "\n",
    "                    # Scale features and make a prediction\n",
    "                    test_features = X_scaler.transform(\n",
    "                        np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1))\n",
    "                    # test_features = X_scaler.transform(np.hstack((shape_feat, hist_feat)).reshape(1, -1))\n",
    "                    test_prediction = svc.predict(test_features)\n",
    "                    if test_prediction == 1:\n",
    "                        xbox_left = xstart + np.int(xleft * scale)\n",
    "                        ytop_draw = np.int(ytop * scale)\n",
    "                        win_draw = np.int(window * scale)\n",
    "                        box_list.append(\n",
    "                            ((xbox_left, ytop_draw + ystart), (xbox_left + win_draw, ytop_draw + win_draw + ystart)))\n",
    "\n",
    "        # Add heat to each box in box list\n",
    "        self.add_heatmap_and_threshold(draw_img, box_list, self.threshold)\n",
    "\n",
    "        # Find final boxes from heatmap using label function\n",
    "        labels = label(self.heatmap)\n",
    "        VehicleDetector.draw_labeled_bboxes(draw_img, labels)\n",
    "\n",
    "        return draw_img\n",
    "\n",
    "    def add_heatmap_and_threshold(self, draw_img, bbox_list, threshold):\n",
    "        heatmap = np.zeros_like(draw_img[:, :, 0]).astype(np.float)\n",
    "\n",
    "        for box in bbox_list:\n",
    "            # Add += 1 for all pixels inside each bbox\n",
    "            # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "            heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "        self.heat_images.append(heatmap)\n",
    "        self.heatmap = np.sum(np.array(self.heat_images), axis=0)\n",
    "        self.heatmap[self.heatmap <= threshold] = 0\n",
    "\n",
    "    @staticmethod\n",
    "    def draw_labeled_bboxes(img, labels):\n",
    "        # Iterate through all detected cars\n",
    "        for car_number in range(1, labels[1] + 1):\n",
    "            # Find pixels with each car_number label value\n",
    "            nonzero = (labels[0] == car_number).nonzero()\n",
    "            # Identify x and y values of those pixels\n",
    "            nonzeroy = np.array(nonzero[0])\n",
    "            nonzerox = np.array(nonzero[1])\n",
    "            # Define a bounding box based on min/max x and y\n",
    "            bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "            # Draw the box on the image\n",
    "            cv2.rectangle(img, bbox[0], bbox[1], (0, 0, 255), 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = VehicleDetector('model-params-hsv2.pk')\n",
    "detector.ystart_ystop_scale = [(380, 480, 1), (400, 600, 1.5), (500, 700, 2.5)]\n",
    "detector.threshold = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_video_output_without_lanes.mp4\n",
      "[MoviePy] Writing video project_video_output_without_lanes.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [27:39<00:01,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_output_without_lanes.mp4 \n",
      "\n",
      "CPU times: user 25min 55s, sys: 40.3 s, total: 26min 35s\n",
      "Wall time: 27min 46s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"project_video_output_without_lanes.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "white_output = 'project_video_output_without_lanes.mp4'\n",
    "clip = VideoFileClip(\"project_video.mp4\")#.subclip(t_start=30,t_end=35)\n",
    "white_clip = clip.fl_image(detector.find_cars)\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
